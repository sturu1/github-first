{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2020_06_22_오후수업.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPoGSmkx1jjwTkg57uLKsjP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sturu1/github-first/blob/master/2020_06_22_%EC%98%A4%ED%9B%84%EC%88%98%EC%97%85.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuaYdQSKtEVH",
        "colab_type": "text"
      },
      "source": [
        "# Fashion MNIST  // 페이지 130\n",
        "\n",
        "1. 70,000 장의 28*28 픽셀의 이미들과 10개의 클래스 정답으로 구성된 데이터셋\n",
        "2. 훈련데이터 60,000장, 테스트데이터 10,000장으로 이루어짐.\n",
        "3. 10개의 클래스 중 하나를 맞추는 문제\n",
        "\n",
        "라벨 | 범주\n",
        "-- | --\n",
        "0 | 티셔츠/상의\n",
        "1 | 바지\n",
        "2 | 스웨터\n",
        "3 | 드레스\n",
        "4 | 코드\n",
        "5 | 샌들\n",
        "6 | 셔츠\n",
        "7 | 운동화\n",
        "8 | 가방\n",
        "9 | 부츠\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IJIwECOtDtB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6361c1e7-aab5-4356-cc59-83e7ecf56d2d"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#데이터를 가져와보자\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist #데이터와 연결\n",
        "(train_X, train_Y), (test_X, test_Y) = fashion_mnist.load_data() # 실제로 데이터 가져옴\n",
        "\n",
        "print(type(train_X))\n",
        "print(len(train_X), len(test_X))\n",
        "print(train_X.shape)\n",
        "\n",
        "#imgidx = 100\n",
        "#plt.imshow(train_X[imgidx], cmap='gray')\n",
        "#plt.colorbar()\n",
        "#plt.show()\n",
        "#print(\"레이블: \", train_Y[imgidx])\n",
        "\n",
        "print(np.max(train_X), np.min(train_X))\n",
        "maxVal = np.max(train_X)\n",
        "\n",
        "#0-1로 스케일로 정규화 code here\n",
        "train_X = train_X / 255.0\n",
        "test_X = test_X / 255.0\n",
        "\n",
        "#모델 정의\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Flatten(input_shape = (28, 28)),\n",
        "                             tf.keras.layers.Dense(units = 128, activation= 'relu'),\n",
        "                             tf.keras.layers.Dense(units = 10, activation= 'softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics = ['accuracy']\n",
        "              )\n",
        "\n",
        "model.summary()\n",
        "\n",
        "#여기서 학습\n",
        "history = model.fit(train_X, train_Y, epochs=25, validation_split=.025)\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "<class 'numpy.ndarray'>\n",
            "60000 10000\n",
            "(60000, 28, 28)\n",
            "255 0\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "1829/1829 [==============================] - 6s 3ms/step - loss: 0.4959 - accuracy: 0.8263 - val_loss: 0.3940 - val_accuracy: 0.8513\n",
            "Epoch 2/25\n",
            "1829/1829 [==============================] - 6s 3ms/step - loss: 0.3723 - accuracy: 0.8645 - val_loss: 0.3832 - val_accuracy: 0.8560\n",
            "Epoch 3/25\n",
            "1829/1829 [==============================] - 6s 3ms/step - loss: 0.3377 - accuracy: 0.8770 - val_loss: 0.3696 - val_accuracy: 0.8673\n",
            "Epoch 4/25\n",
            "1829/1829 [==============================] - 6s 3ms/step - loss: 0.3137 - accuracy: 0.8843 - val_loss: 0.3314 - val_accuracy: 0.8807\n",
            "Epoch 5/25\n",
            "1829/1829 [==============================] - 6s 3ms/step - loss: 0.2937 - accuracy: 0.8917 - val_loss: 0.3210 - val_accuracy: 0.8807\n",
            "Epoch 6/25\n",
            "1829/1829 [==============================] - 6s 3ms/step - loss: 0.2822 - accuracy: 0.8957 - val_loss: 0.3170 - val_accuracy: 0.8867\n",
            "Epoch 7/25\n",
            "1829/1829 [==============================] - 6s 3ms/step - loss: 0.2680 - accuracy: 0.9009 - val_loss: 0.3224 - val_accuracy: 0.8833\n",
            "Epoch 8/25\n",
            "1829/1829 [==============================] - 6s 3ms/step - loss: 0.2580 - accuracy: 0.9036 - val_loss: 0.3103 - val_accuracy: 0.8887\n",
            "Epoch 9/25\n",
            "1829/1829 [==============================] - 6s 3ms/step - loss: 0.2477 - accuracy: 0.9083 - val_loss: 0.3028 - val_accuracy: 0.8907\n",
            "Epoch 10/25\n",
            "1829/1829 [==============================] - 6s 3ms/step - loss: 0.2391 - accuracy: 0.9108 - val_loss: 0.3249 - val_accuracy: 0.8820\n",
            "Epoch 11/25\n",
            "1829/1829 [==============================] - 6s 3ms/step - loss: 0.2310 - accuracy: 0.9131 - val_loss: 0.3216 - val_accuracy: 0.8833\n",
            "Epoch 12/25\n",
            "1829/1829 [==============================] - 6s 3ms/step - loss: 0.2239 - accuracy: 0.9163 - val_loss: 0.3587 - val_accuracy: 0.8747\n",
            "Epoch 13/25\n",
            "1829/1829 [==============================] - 6s 3ms/step - loss: 0.2158 - accuracy: 0.9196 - val_loss: 0.3309 - val_accuracy: 0.8887\n",
            "Epoch 14/25\n",
            "1829/1829 [==============================] - 5s 3ms/step - loss: 0.2077 - accuracy: 0.9219 - val_loss: 0.3501 - val_accuracy: 0.8820\n",
            "Epoch 15/25\n",
            "1829/1829 [==============================] - 5s 3ms/step - loss: 0.2039 - accuracy: 0.9234 - val_loss: 0.3444 - val_accuracy: 0.8893\n",
            "Epoch 16/25\n",
            "1829/1829 [==============================] - 6s 3ms/step - loss: 0.1972 - accuracy: 0.9259 - val_loss: 0.3258 - val_accuracy: 0.8940\n",
            "Epoch 17/25\n",
            "1829/1829 [==============================] - 5s 3ms/step - loss: 0.1919 - accuracy: 0.9277 - val_loss: 0.3486 - val_accuracy: 0.8927\n",
            "Epoch 18/25\n",
            "1829/1829 [==============================] - 5s 3ms/step - loss: 0.1855 - accuracy: 0.9305 - val_loss: 0.3245 - val_accuracy: 0.8967\n",
            "Epoch 19/25\n",
            "1829/1829 [==============================] - 6s 3ms/step - loss: 0.1819 - accuracy: 0.9308 - val_loss: 0.3444 - val_accuracy: 0.8840\n",
            "Epoch 20/25\n",
            "1829/1829 [==============================] - 7s 4ms/step - loss: 0.1764 - accuracy: 0.9342 - val_loss: 0.3358 - val_accuracy: 0.8947\n",
            "Epoch 21/25\n",
            "1829/1829 [==============================] - 6s 3ms/step - loss: 0.1732 - accuracy: 0.9356 - val_loss: 0.3549 - val_accuracy: 0.8873\n",
            "Epoch 22/25\n",
            "1829/1829 [==============================] - 6s 3ms/step - loss: 0.1691 - accuracy: 0.9370 - val_loss: 0.3406 - val_accuracy: 0.8933\n",
            "Epoch 23/25\n",
            "1829/1829 [==============================] - 6s 3ms/step - loss: 0.1653 - accuracy: 0.9379 - val_loss: 0.3646 - val_accuracy: 0.8840\n",
            "Epoch 24/25\n",
            "1829/1829 [==============================] - 6s 3ms/step - loss: 0.1593 - accuracy: 0.9396 - val_loss: 0.3373 - val_accuracy: 0.8947\n",
            "Epoch 25/25\n",
            "1829/1829 [==============================] - 5s 3ms/step - loss: 0.1569 - accuracy: 0.9413 - val_loss: 0.3367 - val_accuracy: 0.8853\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYdPtuhzD9UC",
        "colab_type": "text"
      },
      "source": [
        "# Convolution 알아보기\n",
        "\n",
        "1. 이미지에서 convolution이 어덯게 유용한가?\n",
        "2. Gaussian 스무딩, 부드러운 이미지 만들어 보기\n",
        "3. Sobel 미분필터, X축, Y축 윤곽선 검출해보기\n",
        "\n",
        "sobel filter\n",
        "![대체 텍스트](https://homepages.inf.ed.ac.uk/rbf/HIPR2/figs/sobmasks.gif)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_8fNIHjuuZL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "8caa14b6-3ff9-4684-d511-d91835295647"
      },
      "source": [
        "#다음에 다시할걸\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "#데이터를 가져와보자\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist #데이터와 연결\n",
        "(train_X, train_Y), (test_X, test_Y) = fashion_mnist.load_data() # 실제로 데이터 가져옴\n",
        "\n",
        "#=================filter\n",
        "\n",
        "#sobel filter for dx\n",
        "kernelX = [[-1, 0, 1],\n",
        "           [-2, 0, 2],\n",
        "           [-1, 0, 1]]\n",
        "kernelX = np.array(kernelX)\n",
        "\n",
        "#sobel filter for dy\n",
        "kernelY = [[1, 2, 1],\n",
        "           [0, 0, 0],\n",
        "           [-1, -2, -1]]\n",
        "kernelY = np.array(kernelY)\n",
        "\n",
        "#============ functions\n",
        "\n",
        "#이미지 차원 알려주는 함수\n",
        "def getDimension(x):\n",
        "  return x.shape[0], x.shape[i] #y길이, x길이\n",
        "\n",
        "def convolution(kernel, Img):\n",
        "  kY, kX = getDimension(kernel)\n",
        "  nY, nX = getDimension(Img)\n",
        "\n",
        "  tempImg = np.zeros((nX, nY), dtype = 'float16')\n",
        "\n",
        "  #가장자리를 고려해서 1부터 n-1까지 반복\n",
        "  #image dimension\n",
        "  for j in range(1, nY-1):\n",
        "    for i in range(1,nX-1):\n",
        "      #kernel dimension, itertor k, i\n",
        "      for l in range(0, kY):\n",
        "        for k in range(0, kX):\n",
        "\n",
        "          tempImg[i, j] += Img[i + k-1, j+l-1]* kernel[k, l] #convolution 수행\n",
        "\n",
        "\n",
        "  return tempImg\n",
        "\n",
        "def normalize(x):\n",
        "  return (x - np.min(x)) / (np.max(x)-np.min(x))\n",
        "\n",
        "#============== main code\n",
        "#이미지 하나 불러오기\n",
        "npImg = train_X[0]\n",
        "print(npImg.dtype, npImg.shape, np.max(npImg), np.min(npImg))\n",
        "\n",
        "dX = convolution(kernelX, npImg)\n",
        "#dX = normalize(dX)\n",
        "#print(dX)\n",
        "\n",
        "dY = convolution(kernelY, npImg)\n",
        "#dY = normalize(dY)\n",
        "#print(dY)\n",
        "\n",
        "#magnitude\n",
        "Mag = np.sqrt(dX*dX + dY*dY)\n",
        "\n",
        "dX = dX *255.0 #xcale up\n",
        "dX = dX.astype(np.uint16) #int casting\n",
        "\n",
        "dY = dY *255.0 #xcale up\n",
        "dY = dY.astype(np.uint16) #int casting\n",
        "\n",
        "plt.imshow(dX, camp='gray')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "uint8 (28, 28) 255 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-f60bccf42e15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpImg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpImg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpImg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpImg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0mdX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvolution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernelX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpImg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;31m#dX = normalize(dX)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m#print(dX)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-f60bccf42e15>\u001b[0m in \u001b[0;36mconvolution\u001b[0;34m(kernel, Img)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvolution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m   \u001b[0mkY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetDimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m   \u001b[0mnY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetDimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-f60bccf42e15>\u001b[0m in \u001b[0;36mgetDimension\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m#이미지 차원 알려주는 함수\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetDimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#y길이, x길이\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvolution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'i' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXbEUvgbI33X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}