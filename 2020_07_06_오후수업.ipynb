{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2020_07_06_오후수업.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMoX83IKFkMA3e8try+B5OJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sturu1/github-first/blob/master/2020_07_06_%EC%98%A4%ED%9B%84%EC%88%98%EC%97%85.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clX2cCDajR9V",
        "colab_type": "text"
      },
      "source": [
        "# IMDB dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOAfgQf4hnqR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "outputId": "4af5f68f-12df-4fd8-85e2-78bde08b9f96"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "NUM_WORDS = 10000\n",
        "\n",
        "imdb = tf.keras.datasets.imdb\n",
        "#토큰화. 정수인코딩 텍스트 전처리가 끝난 상태의 데이터를 받을 수 잇음\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words = NUM_WORDS)\n",
        "print(\"첫번째 리뷰데이터: {}\", x_train[0])\n",
        "\n",
        "\n",
        "\n",
        "len_resuit = [len(s) for s in x_train]\n",
        "print(\"리뷰의 최대길이: {} \", format(np.max(len_resuit)))\n",
        "print(\"리뷰의 최소길이: {} \", format(np.min(len_resuit)))\n",
        "\n",
        "#대체적으로 1000이하의 길이를 가지며, 특히 100~500길이를 가진 데이터가 많다\n",
        "#반면, 가장 긴 길이를 가진 데이터는 2000개의 단어수를 넘기도 함\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.boxplot(len_resuit)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(len_resuit, bins=50)\n",
        "plt.show()\n",
        "\n",
        "#Pesore the original sentence from imdb dataset\n",
        "\n",
        "INDEX_FROM = 3\n",
        "word_to_id = imdb.get_word_index()\n",
        "word_to_id = {k:(v+INDEX_FROM) for k, v in word_to_id.items()}\n",
        "word_to_id[\"<PAD>\"] = 0\n",
        "word_to_id[\"<START\"] = 1\n",
        "word_to_id[\"<UNK>\"] = 2\n",
        "word_to_id[\"<UNUSED>\"] = 3\n",
        "\n",
        "id_to_word = {value:key for key, value in word_to_id.items()}\n",
        "print(' '.join(id_to_word[id] for id in x_train[0]))\n",
        "\n",
        "#데이터셋의 입력정보를 맞춰 주기위해서 특정 길이를 잘라줘야함\n",
        "#길이에 못미치는 문장들은 패딩처리 해줘야함\n",
        "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, value = 0, padding = 'pre', maxlen=(32))\n",
        "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test, value = 0, padding = 'pre', maxlen=(32))\n",
        "\n",
        "#훈련, 테스트 데이터를 텐서플로우 라이브러리 tf.data.Dataset을 활용하여 관리\n",
        "#자동으로 셔플링, 배치크리로 나누어서 train_ds, test_ds에 담아둔다\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(1000).batch(32)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n",
        "\n",
        "\n",
        "#------------------------------여기까지 데이터 이야기\n",
        "EPOCHS = 10\n",
        "\n",
        "class MyModel(tf.keras.Model):\n",
        "  #사용할 layer 오브젝트들을 독립적으로 정의\n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "    #길이가 10000인 one-hot 백터를 길이가 16인 feature벡터로 변경\n",
        "    self.emb = tf.keras.layers.Embedding(NUM_WORDS, 64)\n",
        "    self.rnn1 = tf.keras.layers.LSTM(32, input_shape=(64, 1), return_sequences = True)\n",
        "    self.rnn2 = tf.keras.layers.LSTM(32, return_sequences= True)\n",
        "    self.rnn3 = tf.keras.layers.LSTM(32, return_sequences= False)\n",
        "    self.dense = tf.keras.layers.Dense(2, activation = 'softmax')\n",
        "\n",
        "  #x는 입력데이터\n",
        "  #정의된 오브젝트들 같 관계를 만들어줌\n",
        "  def call(self, x, training=None, mask = None):\n",
        "    x = self.emb(x)\n",
        "    x = self.rnn1(x)\n",
        "    x = self.rnn2(x)\n",
        "    x = self.rnn3(x)\n",
        "    x = self.dense(x)\n",
        "    return x\n",
        "\n",
        "def train_step(model, inputs, labels, loss_object, optimizer, train_loss, train_accuracy):\n",
        "  #그래디언트 (미분 값)가 기록됨 #labels(정답)\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(inputs, training = True)\n",
        "    loss = loss_object(labels, predictions)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_accuracy(labels, predictions)\n",
        "\n",
        "def test_step(model, inputs, labels, loss_object, test_loss, test_accuracy):\n",
        "  predictions = model(inputs, training = False)\n",
        "  t_loss = loss_object(labels, predictions)\n",
        "  test_loss(t_loss)\n",
        "  test_accuracy(labels, predictions)\n",
        "\n",
        "#=================== 모델, 학습모듈이 정의되었음\n",
        "\n",
        "#커스텀된 모델 인스천스 생성\n",
        "model = MyModel()\n",
        "#loss_fuction 생성\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "#최적화 함수 받아오기\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "#성능 측정방법 정의\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
        "\n",
        "#=================학습에 필요한 준비물 완료\n",
        "#이제 학습 루틴\n",
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  #훈련데이터 가져와서 학습\n",
        "  for seqs, labels in train_ds:\n",
        "    train_step(model, seqs, labels, loss_object, optimizer, train_loss, train_accuracy)\n",
        "\n",
        "  #테스트데이터 가져와서 테스트 및 정확도 측정\n",
        "  for seqs, labels in test_ds:\n",
        "    test_step(model, seqs, labels, loss_object, train_loss, train_accuracy)\n",
        "\n",
        "  templete = 'epoch {}, loss: {}, acc: {}, test_loss: {}, test_acc: {}'\n",
        "  print(templete.format(epoch+1,\n",
        "                        train_loss.result(),\n",
        "                        train_accuracy.result(),\n",
        "                        train_loss.result(),\n",
        "                        test_accuracy.result()\n",
        "                        ))\n",
        "\n",
        "train_loss.reset_states()\n",
        "train_accuracy.reset_states()\n",
        "train_loss.reset_states()\n",
        "test_accuracy.reset_states()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "첫번째 리뷰데이터: {} [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
            "리뷰의 최대길이: {}  2494\n",
            "리뷰의 최소길이: {}  11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "<START this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
            "epoch 1, loss: 0.4766955077648163, acc: 0.763979971408844, test_loss: 0.4766955077648163, test_acc: 0.0\n",
            "epoch 2, loss: 0.4465150535106659, acc: 0.7896299958229065, test_loss: 0.4465150535106659, test_acc: 0.0\n",
            "epoch 3, loss: 0.44421204924583435, acc: 0.8025000095367432, test_loss: 0.44421204924583435, test_acc: 0.0\n",
            "epoch 4, loss: 0.4534972608089447, acc: 0.8102999925613403, test_loss: 0.4534972608089447, test_acc: 0.0\n",
            "epoch 5, loss: 0.4821484386920929, acc: 0.8193240165710449, test_loss: 0.4821484386920929, test_acc: 0.0\n",
            "epoch 6, loss: 0.5034161806106567, acc: 0.8258166909217834, test_loss: 0.5034161806106567, test_acc: 0.0\n",
            "epoch 7, loss: 0.5179847478866577, acc: 0.8319028615951538, test_loss: 0.5179847478866577, test_acc: 0.0\n",
            "epoch 8, loss: 0.5348252058029175, acc: 0.8361600041389465, test_loss: 0.5348252058029175, test_acc: 0.0\n",
            "epoch 9, loss: 0.5536158680915833, acc: 0.839900016784668, test_loss: 0.5536158680915833, test_acc: 0.0\n",
            "epoch 10, loss: 0.5726838111877441, acc: 0.8425639867782593, test_loss: 0.5726838111877441, test_acc: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYet5rqhvZjc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Sq4rz6kJ-lz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}